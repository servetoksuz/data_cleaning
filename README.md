# data_cleaning
In this step of the project, I acquire, clean and wrangle the data. The data was the US Accident data from 2016 - 2019 from 49 states (excluding Hawaii). In this dataset, there are 1048575 rows and 49 columns. Each row represents each incident, and the rows represent the variables associated with each incident.

After uploading the csv file to the Jupyter notebook, I use df.head() to see the first 5 rows ad df.info() to see the name of the columns and the type of the data in each column. One of the major issues with this dataframe is two columns: 'End_Lat', 'End_Lng' have no information in it. So, I used the drop columns function to remove those two columns. The start time and the End time of the accidents are datetime objects, and I extracted the year, month, date, day, hour, and week day from the Start time column. Since there is not a big difference in start and end times, I used the extraction only once. Now the new dataframe has 52 columns.

Another issue is some of the columns have missing values or NaN values that prevents summary statistics in the future. I first tried to model a linear regression model but the linear regression model failed because of these NaN values. I used fillna function with mean method for numerical variables and “NaN” with categorical variables. For some values as the temperature or wind chill, I used the ‘groupby’ function to replace the missing values by the mean of that particular state. Before filling each missing cells, I made a new column with 0 or 1 values.

The purpose of replacing all missing cells is to generate a regression model. Since the project is about predicting the severity of an accident, I used “Severity” as my target variable.  I did not include the columns which have objects as type in the feature variables. Also, I did not include the datetime variables in my feature variables since the days, years and months are cyclical and not linear. After defining the feature variables and the target variable, we have 153 feature variables and one target variable.

For the future, I used train_test_split and linear regression models from sklearn library. I have started with a score of 0.32 and in the future, I will try to increase this score with future data wrangling techniques.
